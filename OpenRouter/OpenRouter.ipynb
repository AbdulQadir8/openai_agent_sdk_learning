{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install OpenAI Agents Dep."
      ],
      "metadata": {
        "id": "27vjStPrO98v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts5ta83hOHDw",
        "outputId": "6659807e-6d8f-4ef6-8da8-edee6c38c9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "YUaXOciuPK3I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Provider Config"
      ],
      "metadata": {
        "id": "AJR-gZm9PUR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')"
      ],
      "metadata": {
        "id": "boOD9MfAPQsh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference: https://openrouter.ai/docs/quickstart\n",
        "\n",
        "BASE_URL  = \"https://openrouter.ai/api/v1\"\n",
        "MODEL = \"google/gemini-2.0-flash-lite-001\"\n",
        "#  Some other free models on 26th March:\n",
        "# https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free\n",
        "# https://openrouter.ai/google/gemini-2.5-pro-exp-03-25:free"
      ],
      "metadata": {
        "id": "CIc7YsXQPmOC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the OpenRouter API directly"
      ],
      "metadata": {
        "id": "B19Sz6O8mXRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "response = requests.post(\n",
        "    url=f\"{BASE_URL}/chat/completions\",\n",
        "    headers={\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\"\n",
        "    },\n",
        "    data=json.dumps({\n",
        "        \"model\":MODEL,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}],\n",
        "    })\n",
        ")\n",
        "\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fYAY_2LPu1_",
        "outputId": "f8a6a26a-9e3b-4ccc-e52f-f3b7b0fe8cbc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'gen-1745043162-pwgyNdJLW8IRmPHbErif', 'provider': 'Google AI Studio', 'model': 'google/gemini-2.0-flash-lite-001', 'object': 'chat.completion', 'created': 1745043162, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'STOP', 'index': 0, 'message': {'role': 'assistant', 'content': 'The Los Angeles Dodgers won the World Series in 2020.\\n', 'refusal': None, 'reasoning': None}}], 'usage': {'prompt_tokens': 12, 'completion_tokens': 16, 'total_tokens': 28}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = response.json()\n",
        "data[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "22trSzfvpMeA",
        "outputId": "deca2269-7fd1-4125-886f-d216701cfc5a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Los Angeles Dodgers won the World Series in 2020.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Using OpenAI Agents SDK"
      ],
      "metadata": {
        "id": "wRoXZc8xplpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel, set_tracing_disabled, Runner\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        "    base_url=BASE_URL,\n",
        ")\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "\n",
        "async def run_agent():\n",
        "    agent = Agent(\n",
        "        name=\"Assitant\",\n",
        "        instructions=\"You only respond in haikus\",\n",
        "        model=OpenAIChatCompletionsModel(model=MODEL,\n",
        "                                         openai_client=client))\n",
        "\n",
        "    result = await Runner.run(\n",
        "        agent,\n",
        "        \"Tell me about recursion in programming\",\n",
        "    )\n",
        "    print(result.final_output)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(run_agent())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxInVFBJnrlt",
        "outputId": "e83824f0-ed08-48e7-d9b3-d674f41bd8b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A function calls self,\n",
            "Breaking work in smaller parts,\n",
            "Ends with base defined. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "deedsvL2yEV8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}